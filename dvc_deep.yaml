stages:
  prepare_data:
    cmd: python experiment/prepare_data.py
    outs:
      - assets/data/df.csv
      - assets/data/splits/train/raw.csv
      - assets/data/splits/test/raw.csv

  preprocessing:
    cmd: python experiment/preprocessing.py
    outs:
      - assets/data/splits/train/preprocessed.csv
    deps:
      - assets/data/splits/train/raw.csv


  create_word_embeddings:
    cmd: python experiment/supervised_deep_models/create_word_embeddings.py
    deps:
      - assets/data/splits/train/preprocessed.csv
    outs:
      - assets/deep_assets/word2vec.model

  preprocessing_deep:
    cmd: python experiment/supervised_deep_models/preprocessing_for_deep.py
    deps:
      - assets/data/splits/train/preprocessed.csv

    outs:
      - assets/data/splits/train/padded.csv

  tuning_eval_models:
    cmd: python experiment/supervised_deep_models/tuning_eval_models.py
    deps:
      - assets/data/splits/train/padded.csv
      - assets/deep_assets/word2vec.model
      - assets/deep_assets/tokenizer.json
    outs:
      - assets/deep_assets/lstm_model

  apply_model:
    cmd: python experiment/supervised_deep_models/apply_model.py
    deps:
      - assets/data/splits/test/raw.csv
      - assets/deep_assets/word2vec.model
      - assets/deep_assets/tokenizer.json
      - assets/deep_assets/lstm_model
    outs:
      - assets/deep_assets/predictions.csv