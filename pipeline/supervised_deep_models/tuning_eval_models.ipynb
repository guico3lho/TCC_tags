{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Packages and Assets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping\n",
    "import seaborn as sns\n",
    "import keras_tuner as kt\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing.text import tokenizer_from_json\n",
    "import os, sys"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guilherme\\.conda\\envs\\nlp2\\python.exe\n",
      "C:\\Users\\Guilherme\\Documents\\Programming\\Python\\DataScience\\TCC\\pipeline\\supervised_lstm_model\n"
     ]
    }
   ],
   "source": [
    "print(sys.executable)\n",
    "print(os.getcwd())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dependencies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "with open('../../assets/lstm_assets/tokenizer.json', 'r', encoding='utf-8') as f:\n",
    "    tokenizer_json = f.read()\n",
    "    tokenizer = tokenizer_from_json(tokenizer_json)\n",
    "    word_index = tokenizer.word_index\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_we = Word2Vec.load('../../assets/lstm_assets/word2vec.model')\n",
    "\n",
    "print(model_we.wv.most_similar('itau'))\n",
    "\n",
    "# List of nparrays of size 300\n",
    "embeddings_dict = {}\n",
    "for word in model_we.wv.index_to_key:\n",
    "    embeddings_dict[word] = model_we.wv[word]\n",
    "\n",
    "embeddings_on_this_context = np.zeros((len(word_index), 300))\n",
    "for word, i in word_index.items():\n",
    "    embeddings_vector = embeddings_dict.get(word)\n",
    "    if embeddings_vector is not None:\n",
    "        embeddings_on_this_context[i - 1] = embeddings_vector\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train = pd.read_csv('../../assets/data/splits/train/padded.csv')\n",
    "val = pd.read_csv('../../assets/data/splits/val/padded.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def index2word(word_index):\n",
    "    index_word = {}\n",
    "    for key in word_index:\n",
    "        index_word[word_index[key]] = key\n",
    "    return index_word\n",
    "\n",
    "\n",
    "def seq2text(seq, index_word):\n",
    "    text = []\n",
    "    for index in seq:\n",
    "        text.append(index_word[index])\n",
    "    return text\n",
    "\n",
    "\n",
    "def show_confusion_matrix(cm):\n",
    "    print(\"Confusion Matrix\")\n",
    "    plt.figure(figsize=(10, 7))\n",
    "\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'],\n",
    "                yticklabels=['Negative', 'Positive'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Truth')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RNN Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data transformation for model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train = train.to_numpy()[:, :-1]\n",
    "y_train = train.to_numpy()[:, -1]\n",
    "\n",
    "X_val = val.to_numpy()[:, :-1]\n",
    "y_val = val.to_numpy()[:, -1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Without Tuning and Early stopping"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# model = Sequential([\n",
    "#     Embedding(input_dim=len(word_index), output_dim= 300, input_length=X_train.shape[1], trainable=False, weights=[embeddings_on_this_context]),\n",
    "#     Bidirectional(LSTM(64, return_sequences=True)),\n",
    "#     # Dropout(0.4),\n",
    "#     # Bidirectional(LSTM(hp.Choice('units',[32,64]))),\n",
    "#     Bidirectional(LSTM(64)),\n",
    "#     Dense(32, activation='relu'),\n",
    "#     # Dropout(0.6),\n",
    "#     Dense(4, activation='softmax')\n",
    "# ])\n",
    "#\n",
    "# model.summary()\n",
    "\n",
    "# from keras.optimizers import SGD\n",
    "#\n",
    "# loss = \"sparse_categorical_crossentropy\"\n",
    "# optimizer = SGD(learning_rate=0.01)\n",
    "# metrics = ['accuracy']\n",
    "#\n",
    "# model.compile(loss=loss,optimizer=optimizer,metrics=metrics)\n",
    "# history = model.fit(X_train, y_train, epochs=25, validation_data=(X_val,y_val), verbose=2)\n",
    "\n",
    "# history = model.fit(X_train, y_train, epochs=4000, validation_data=(X_val,y_val), verbose=2, callbacks=[es])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tuning Architecture Hyperparams using RandomSearch and Early Stopping"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=len(word_index), output_dim=300, input_length=X_train.shape[1], trainable=False,\n",
    "                  weights=[embeddings_on_this_context]),\n",
    "        Bidirectional(LSTM(32, return_sequences=True)),\n",
    "        Dropout(0.29),\n",
    "        Bidirectional(LSTM(16)),\n",
    "        Dense(64, 'tanh'),\n",
    "        Dropout(0.73),\n",
    "        Dense(4, activation='softmax')\n",
    "    ])\n",
    "    loss = \"sparse_categorical_crossentropy\"\n",
    "    # optimizer = SGD(learning_rate=0.01)\n",
    "    metrics = ['accuracy']\n",
    "\n",
    "    model.compile(loss=loss, optimizer=hp.Choice('optimizer', ['adam', 'sgd', 'rmsprop']), metrics=metrics)\n",
    "    return model\n",
    "\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# def build_model(hp):\n",
    "#     model = Sequential([\n",
    "#     Embedding(input_dim=len(word_index), output_dim= 300, input_length=X_train.shape[1], trainable=False, weights=[embeddings_on_this_context]),\n",
    "#     Bidirectional(LSTM(hp.Choice('units_bilstm_1',[16,32,64]), return_sequences=True)),\n",
    "#     Dropout(hp.Float('rate_dp_1',0.5,0.9,step=0.1,default=0.5)),\n",
    "#     Bidirectional(LSTM(hp.Choice('units_bilstm_2',[16,32,64]))),\n",
    "#     Dense(hp.Choice('units_dense',[16,32,64]), hp.Choice('activation',['relu','sigmoid','tanh']) ),\n",
    "#     Dropout(hp.Float('rate_dp_2',0.5,0.9,step=0.1,default=0.5)),\n",
    "#     Dense(4, activation='softmax')\n",
    "# ])\n",
    "#     loss = \"sparse_categorical_crossentropy\"\n",
    "#     # optimizer = SGD(learning_rate=0.01)\n",
    "#     metrics = ['accuracy']\n",
    "#\n",
    "#     model.compile(loss=loss,optimizer=hp.Choice('optimizer',['adam','sgd','rmsprop']),metrics=metrics)\n",
    "#     return model\n",
    "#\n",
    "# es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 7\n",
      "units_bilstm_1 (Choice)\n",
      "{'default': 16, 'conditions': [], 'values': [16, 32, 64], 'ordered': True}\n",
      "rate_dp_1 (Float)\n",
      "{'default': 0.5, 'conditions': [], 'min_value': 0.5, 'max_value': 0.9, 'step': 0.1, 'sampling': 'linear'}\n",
      "units_bilstm_2 (Choice)\n",
      "{'default': 16, 'conditions': [], 'values': [16, 32, 64], 'ordered': True}\n",
      "units_dense (Choice)\n",
      "{'default': 16, 'conditions': [], 'values': [16, 32, 64], 'ordered': True}\n",
      "activation (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'sigmoid', 'tanh'], 'ordered': False}\n",
      "rate_dp_2 (Float)\n",
      "{'default': 0.5, 'conditions': [], 'min_value': 0.5, 'max_value': 0.9, 'step': 0.1, 'sampling': 'linear'}\n",
      "optimizer (Choice)\n",
      "{'default': 'adam', 'conditions': [], 'values': ['adam', 'sgd', 'rmsprop'], 'ordered': False}\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=3,\n",
    "    executions_per_trial=1,\n",
    "    directory='../../assets/lstm_assets',\n",
    "    project_name='lstm_tuning')\n",
    "\n",
    "tuner.search_space_summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 01m 07s]\n",
      "val_accuracy: 0.3569042384624481\n",
      "\n",
      "Best val_accuracy So Far: 0.7989977598190308\n",
      "Total elapsed time: 00h 06m 29s\n",
      "\n",
      "Search: Running Trial #3\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "32                |16                |units_bilstm_1\n",
      "0.8               |0.6               |rate_dp_1\n",
      "32                |16                |units_bilstm_2\n",
      "32                |32                |units_dense\n",
      "relu              |relu              |activation\n",
      "0.6               |0.5               |rate_dp_2\n",
      "adam              |sgd               |optimizer\n",
      "\n",
      "Epoch 1/4000\n",
      "449/449 [==============================] - 16s 20ms/step - loss: 0.9997 - accuracy: 0.6030 - val_loss: 0.7405 - val_accuracy: 0.7127\n",
      "Epoch 2/4000\n",
      "449/449 [==============================] - 10s 22ms/step - loss: 0.7439 - accuracy: 0.7338 - val_loss: 0.6515 - val_accuracy: 0.7517\n",
      "Epoch 3/4000\n",
      "449/449 [==============================] - 10s 22ms/step - loss: 0.6762 - accuracy: 0.7623 - val_loss: 0.6393 - val_accuracy: 0.7628\n",
      "Epoch 4/4000\n",
      "449/449 [==============================] - 6s 13ms/step - loss: 0.6435 - accuracy: 0.7719 - val_loss: 0.6206 - val_accuracy: 0.7606\n",
      "Epoch 5/4000\n",
      "449/449 [==============================] - 8s 17ms/step - loss: 0.6221 - accuracy: 0.7822 - val_loss: 0.6023 - val_accuracy: 0.7773\n",
      "Epoch 6/4000\n",
      "449/449 [==============================] - 8s 17ms/step - loss: 0.6003 - accuracy: 0.7868 - val_loss: 0.5777 - val_accuracy: 0.7906\n",
      "Epoch 7/4000\n",
      "449/449 [==============================] - 7s 16ms/step - loss: 0.5851 - accuracy: 0.7925 - val_loss: 0.5687 - val_accuracy: 0.7945\n",
      "Epoch 8/4000\n",
      "449/449 [==============================] - 8s 18ms/step - loss: 0.5748 - accuracy: 0.7990 - val_loss: 0.5739 - val_accuracy: 0.7968\n",
      "Epoch 9/4000\n",
      "449/449 [==============================] - 6s 14ms/step - loss: 0.5650 - accuracy: 0.7984 - val_loss: 0.5746 - val_accuracy: 0.7940\n",
      "Epoch 10/4000\n",
      "449/449 [==============================] - 9s 19ms/step - loss: 0.5610 - accuracy: 0.8024 - val_loss: 0.5604 - val_accuracy: 0.8057\n",
      "Epoch 11/4000\n",
      "449/449 [==============================] - 8s 18ms/step - loss: 0.5588 - accuracy: 0.8076 - val_loss: 0.5587 - val_accuracy: 0.8057\n",
      "Epoch 12/4000\n",
      "449/449 [==============================] - 8s 18ms/step - loss: 0.5537 - accuracy: 0.8073 - val_loss: 0.5536 - val_accuracy: 0.7990\n",
      "Epoch 13/4000\n",
      "449/449 [==============================] - 8s 17ms/step - loss: 0.5534 - accuracy: 0.8047 - val_loss: 0.5711 - val_accuracy: 0.7934\n",
      "Epoch 14/4000\n",
      "449/449 [==============================] - 9s 20ms/step - loss: 0.5431 - accuracy: 0.8123 - val_loss: 0.5344 - val_accuracy: 0.8085\n",
      "Epoch 15/4000\n",
      "449/449 [==============================] - 6s 14ms/step - loss: 0.5304 - accuracy: 0.8108 - val_loss: 0.5394 - val_accuracy: 0.8068\n",
      "Epoch 16/4000\n",
      "449/449 [==============================] - 8s 19ms/step - loss: 0.5278 - accuracy: 0.8136 - val_loss: 0.5520 - val_accuracy: 0.8096\n",
      "Epoch 17/4000\n",
      "449/449 [==============================] - 8s 18ms/step - loss: 0.5342 - accuracy: 0.8118 - val_loss: 0.5369 - val_accuracy: 0.8124\n",
      "Epoch 18/4000\n",
      "449/449 [==============================] - 8s 19ms/step - loss: 0.5246 - accuracy: 0.8160 - val_loss: 0.5328 - val_accuracy: 0.8207\n",
      "Epoch 19/4000\n",
      "449/449 [==============================] - 6s 14ms/step - loss: 0.5257 - accuracy: 0.8148 - val_loss: 0.5384 - val_accuracy: 0.8090\n",
      "Epoch 20/4000\n",
      "449/449 [==============================] - 6s 14ms/step - loss: 0.5224 - accuracy: 0.8164 - val_loss: 0.5417 - val_accuracy: 0.8129\n",
      "Epoch 21/4000\n",
      "449/449 [==============================] - 6s 14ms/step - loss: 0.5116 - accuracy: 0.8200 - val_loss: 0.5274 - val_accuracy: 0.8168\n",
      "Epoch 22/4000\n",
      "449/449 [==============================] - 6s 13ms/step - loss: 0.5176 - accuracy: 0.8163 - val_loss: 0.5268 - val_accuracy: 0.8185\n",
      "Epoch 23/4000\n",
      "449/449 [==============================] - 8s 18ms/step - loss: 0.5090 - accuracy: 0.8202 - val_loss: 0.5331 - val_accuracy: 0.8163\n",
      "Epoch 24/4000\n",
      "449/449 [==============================] - 7s 15ms/step - loss: 0.5012 - accuracy: 0.8212 - val_loss: 0.5233 - val_accuracy: 0.8190\n",
      "Epoch 25/4000\n",
      "449/449 [==============================] - 6s 14ms/step - loss: 0.5019 - accuracy: 0.8244 - val_loss: 0.5268 - val_accuracy: 0.8202\n",
      "Epoch 26/4000\n",
      "449/449 [==============================] - 7s 15ms/step - loss: 0.5011 - accuracy: 0.8246 - val_loss: 0.5353 - val_accuracy: 0.8202\n",
      "Epoch 27/4000\n",
      "449/449 [==============================] - 6s 14ms/step - loss: 0.5002 - accuracy: 0.8268 - val_loss: 0.5293 - val_accuracy: 0.8218\n",
      "Epoch 28/4000\n",
      "449/449 [==============================] - 6s 14ms/step - loss: 0.4964 - accuracy: 0.8288 - val_loss: 0.5160 - val_accuracy: 0.8185\n",
      "Epoch 29/4000\n",
      "449/449 [==============================] - 7s 15ms/step - loss: 0.4957 - accuracy: 0.8262 - val_loss: 0.5387 - val_accuracy: 0.8112\n",
      "Epoch 30/4000\n",
      "449/449 [==============================] - 6s 14ms/step - loss: 0.4892 - accuracy: 0.8282 - val_loss: 0.5216 - val_accuracy: 0.8168\n",
      "Epoch 31/4000\n",
      "449/449 [==============================] - 6s 14ms/step - loss: 0.4915 - accuracy: 0.8263 - val_loss: 0.5385 - val_accuracy: 0.8062\n",
      "Epoch 32/4000\n",
      "449/449 [==============================] - 6s 14ms/step - loss: 0.4834 - accuracy: 0.8296 - val_loss: 0.5504 - val_accuracy: 0.8135\n",
      "Epoch 33/4000\n",
      "449/449 [==============================] - 6s 13ms/step - loss: 0.4788 - accuracy: 0.8287 - val_loss: 0.5118 - val_accuracy: 0.8185\n",
      "Epoch 34/4000\n",
      "449/449 [==============================] - 6s 13ms/step - loss: 0.4807 - accuracy: 0.8316 - val_loss: 0.5200 - val_accuracy: 0.8185\n",
      "Epoch 35/4000\n",
      " 78/449 [====>.........................] - ETA: 4s - loss: 0.4829 - accuracy: 0.8297"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train, epochs=4000, validation_split=0.1, callbacks=[es])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_model = tuner.get_best_models()[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "ax1.plot(tuner.history['accuracy'])\n",
    "ax1.plot(tuner.history['val_accuracy'])\n",
    "ax1.set_title('Model Accuracy')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "ax2.plot(tuner.history['loss'])\n",
    "ax2.plot(tuner.history['val_loss'])\n",
    "ax2.set_title('Model Loss')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tuning fit hyperparamters using GridSearch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def architecture_tuned_model():\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=len(word_index), output_dim=300, input_length=X_train.shape[1], trainable=False,\n",
    "                  weights=[embeddings_on_this_context]),\n",
    "        Bidirectional(LSTM(32, return_sequences=True)),\n",
    "        Dropout(0.29),\n",
    "        Bidirectional(LSTM(16)),\n",
    "        Dense(64, 'tanh'),\n",
    "        Dropout(0.73),\n",
    "        Dense(4, activation='softmax')\n",
    "    ])\n",
    "    loss = \"sparse_categorical_crossentropy\"\n",
    "    optimizer = SGD(learning_rate=0.01)\n",
    "    metrics = ['accuracy']\n",
    "\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "model = KerasClassifier(model=architecture_tuned_model, verbose=2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'batch_size': [32, 64, 128]}\n",
    "\n",
    "gs = GridSearchCV(estimator=model,\n",
    "                  param_grid=param_grid,\n",
    "                  cv=5)\n",
    "gs.fit(X_train, y_train)\n",
    "print(f\"Best results for {model.__class__.__name__}\")\n",
    "print(\"Best Score of train set: \" + str(gs.best_score_))\n",
    "print(\"Best estimator: \" + str(gs.best_estimator_))\n",
    "print(\"Best parameter set: \" + str(gs.best_params_))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Exporting model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save('../../assets/lstm_assets/lstm_model')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
