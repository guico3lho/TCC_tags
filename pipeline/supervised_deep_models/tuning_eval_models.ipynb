{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Packages and Assets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping\n",
    "import seaborn as sns\n",
    "import keras_tuner as kt\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.metrics import Accuracy, Precision, Recall\n",
    "from keras.preprocessing.text import tokenizer_from_json\n",
    "import os, sys\n",
    "\n",
    "\n",
    "import keras.backend as K"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-22T00:39:05.190767Z",
     "start_time": "2023-05-22T00:39:05.166716700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guilherme\\.conda\\envs\\nlp2\\python.exe\n",
      "C:\\Users\\Guilherme\\Documents\\Programming\\Python\\DataScience\\TCC\\pipeline\\supervised_deep_models\n"
     ]
    }
   ],
   "source": [
    "print(sys.executable)\n",
    "print(os.getcwd())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dependencies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "with open('../../assets/deep_assets/tokenizer.json', 'r', encoding='utf-8') as f:\n",
    "    tokenizer_json = f.read()\n",
    "    tokenizer = tokenizer_from_json(tokenizer_json)\n",
    "    word_index = tokenizer.word_index\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('itub4', 0.990408718585968), ('banco', 0.9718618392944336), ('bradesco', 0.9700526595115662), ('bbas3', 0.9663271307945251), ('bbdc4', 0.9616492986679077), ('santander', 0.9615459442138672), ('xpbr31', 0.9500864148139954), ('unibanco', 0.9492729902267456), ('pagar', 0.9354850649833679), ('valioso', 0.9320330619812012)]\n"
     ]
    }
   ],
   "source": [
    "model_we = Word2Vec.load('../../assets/deep_assets/word2vec.model')\n",
    "\n",
    "print(model_we.wv.most_similar('itau'))\n",
    "\n",
    "# List of nparrays of size 300\n",
    "embeddings_dict = {}\n",
    "for word in model_we.wv.index_to_key:\n",
    "    embeddings_dict[word] = model_we.wv[word]\n",
    "\n",
    "embeddings_on_this_context = np.zeros((len(word_index), 300))\n",
    "for word, i in word_index.items():\n",
    "    embeddings_vector = embeddings_dict.get(word)\n",
    "    if embeddings_vector is not None:\n",
    "        embeddings_on_this_context[i - 1] = embeddings_vector\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "train = pd.read_csv('../../assets/data/splits/train/padded.csv')\n",
    "val = pd.read_csv('../../assets/data/splits/val/padded.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-22T00:22:47.060904900Z",
     "start_time": "2023-05-22T00:22:47.007921500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def index2word(word_index):\n",
    "    index_word = {}\n",
    "    for key in word_index:\n",
    "        index_word[word_index[key]] = key\n",
    "    return index_word\n",
    "\n",
    "\n",
    "def seq2text(seq, index_word):\n",
    "    text = []\n",
    "    for index in seq:\n",
    "        text.append(index_word[index])\n",
    "    return text\n",
    "\n",
    "\n",
    "def show_confusion_matrix(cm):\n",
    "    print(\"Confusion Matrix\")\n",
    "    plt.figure(figsize=(10, 7))\n",
    "\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'],\n",
    "                yticklabels=['Negative', 'Positive'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Truth')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-22T00:34:50.771100200Z",
     "start_time": "2023-05-22T00:34:50.758107700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RNN Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data transformation for model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "X_train = train.to_numpy()[:, :-1]\n",
    "X_val = val.to_numpy()[:, :-1]\n",
    "y_train = train.to_numpy()[:, -1]\n",
    "y_val = val.to_numpy()[:, -1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-22T00:22:49.470798Z",
     "start_time": "2023-05-22T00:22:49.447811500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tuning Architecture Hyperparams using RandomSearch and Early Stopping"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Test 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# def build_model(hp):\n",
    "#     model = Sequential([\n",
    "#         Embedding(input_dim=len(word_index), output_dim=300, input_length=X_train.shape[1], trainable=False,\n",
    "#                   weights=[embeddings_on_this_context]),\n",
    "#         Bidirectional(LSTM(16, return_sequences=True)),\n",
    "#         Dropout(hp.Float('rate_dp_1', 0, 0.4, step=0.1)),\n",
    "#         Bidirectional(LSTM(16)),\n",
    "#         Dense(64, 'tanh'),\n",
    "#         Dropout(hp.Float('rate_dp_1', 0.1, 0.4, step=0.1)),\n",
    "#         Dense(4, activation='softmax')\n",
    "#     ])\n",
    "#     loss = \"sparse_categorical_crossentropy\"\n",
    "#     # optimizer = SGD(learning_rate=0.01)\n",
    "#     metrics = ['accuracy']\n",
    "#\n",
    "#     model.compile(loss=loss, optimizer='adam', metrics=metrics)\n",
    "#     return model\n",
    "#\n",
    "#\n",
    "# es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "f1_score() missing 2 required positional arguments: 'y_true' and 'y_pred'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[31], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mf1_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mTypeError\u001B[0m: f1_score() missing 2 required positional arguments: 'y_true' and 'y_pred'"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-22T00:28:49.771275800Z",
     "start_time": "2023-05-22T00:28:49.715308500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "####  Test 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential([\n",
    "    Embedding(input_dim=len(word_index), output_dim= 300, input_length=X_train.shape[1], trainable=False, weights=[embeddings_on_this_context]),\n",
    "    Bidirectional(LSTM(hp.Choice('units_bilstm_1',[16,32,64]), return_sequences=True)),\n",
    "    Dropout(hp.Float('rate_dp_1',0,0.3,step=0.1)),\n",
    "    Bidirectional(LSTM(hp.Choice('units_bilstm_2',[16,32,64]))),\n",
    "    Dense(hp.Choice('units_dense',[16,32,64]), hp.Choice('activation',['tanh']) ),\n",
    "    Dropout(hp.Float('rate_dp_2',0,0.3,step=0.1)),\n",
    "    Dense(4, activation='softmax')\n",
    "])\n",
    "    loss = \"sparse_categorical_crossentropy\"\n",
    "    # optimizer = SGD(learning_rate=0.01)\n",
    "    metrics = ['accuracy']\n",
    "    # metrics = ['accuracy', Precision(), Recall()]\n",
    "\n",
    "    model.compile(loss=loss,optimizer='adam',metrics=metrics)\n",
    "    return model\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-22T00:44:47.413576100Z",
     "start_time": "2023-05-22T00:44:47.384593300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 6\n",
      "units_bilstm_1 (Choice)\n",
      "{'default': 16, 'conditions': [], 'values': [16, 32, 64], 'ordered': True}\n",
      "rate_dp_1 (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.3, 'step': 0.1, 'sampling': 'linear'}\n",
      "units_bilstm_2 (Choice)\n",
      "{'default': 16, 'conditions': [], 'values': [16, 32, 64], 'ordered': True}\n",
      "units_dense (Choice)\n",
      "{'default': 16, 'conditions': [], 'values': [16, 32, 64], 'ordered': True}\n",
      "activation (Choice)\n",
      "{'default': 'tanh', 'conditions': [], 'values': ['tanh'], 'ordered': False}\n",
      "rate_dp_2 (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.3, 'step': 0.1, 'sampling': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# amanha testar dropout 0.0, 0.1, 0.2\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    directory='../../assets/deep_assets',\n",
    "    overwrite=True,\n",
    "    project_name='lstm_tuning')\n",
    "\n",
    "tuner.search_space_summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-22T00:44:51.234091800Z",
     "start_time": "2023-05-22T00:44:49.149302200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 02m 48s]\n",
      "val_accuracy: 0.8378678560256958\n",
      "\n",
      "Best val_accuracy So Far: 0.8378678560256958\n",
      "Total elapsed time: 00h 12m 16s\n",
      "\n",
      "Search: Running Trial #6\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "16                |64                |units_bilstm_1\n",
      "0                 |0                 |rate_dp_1\n",
      "16                |64                |units_bilstm_2\n",
      "64                |32                |units_dense\n",
      "tanh              |tanh              |activation\n",
      "0.1               |0.1               |rate_dp_2\n",
      "\n",
      "Epoch 1/4000\n",
      "451/451 - 13s - loss: 0.9301 - accuracy: 0.6300 - val_loss: 0.7751 - val_accuracy: 0.7152 - 13s/epoch - 30ms/step\n",
      "Epoch 2/4000\n",
      "451/451 - 6s - loss: 0.7232 - accuracy: 0.7291 - val_loss: 0.7454 - val_accuracy: 0.7185 - 6s/epoch - 13ms/step\n",
      "Epoch 3/4000\n",
      "451/451 - 5s - loss: 0.6306 - accuracy: 0.7725 - val_loss: 0.6073 - val_accuracy: 0.7835 - 5s/epoch - 11ms/step\n",
      "Epoch 4/4000\n",
      "451/451 - 5s - loss: 0.5773 - accuracy: 0.7914 - val_loss: 0.5758 - val_accuracy: 0.7996 - 5s/epoch - 11ms/step\n",
      "Epoch 5/4000\n",
      "451/451 - 5s - loss: 0.5503 - accuracy: 0.8020 - val_loss: 0.5369 - val_accuracy: 0.8051 - 5s/epoch - 11ms/step\n",
      "Epoch 6/4000\n",
      "451/451 - 5s - loss: 0.5312 - accuracy: 0.8082 - val_loss: 0.5241 - val_accuracy: 0.8140 - 5s/epoch - 10ms/step\n",
      "Epoch 7/4000\n",
      "451/451 - 5s - loss: 0.5178 - accuracy: 0.8142 - val_loss: 0.5218 - val_accuracy: 0.8251 - 5s/epoch - 11ms/step\n",
      "Epoch 8/4000\n",
      "451/451 - 4s - loss: 0.5031 - accuracy: 0.8182 - val_loss: 0.5076 - val_accuracy: 0.8212 - 4s/epoch - 10ms/step\n",
      "Epoch 9/4000\n",
      "451/451 - 5s - loss: 0.4938 - accuracy: 0.8230 - val_loss: 0.5287 - val_accuracy: 0.8207 - 5s/epoch - 10ms/step\n",
      "Epoch 10/4000\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train, epochs=4000, validation_data=(X_val,y_val), callbacks=[es], batch_size=32, verbose=2)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tuner.results_summary()\n",
    " # 0.845774233341217"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-22T00:20:25.579832400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "type(tuner.results_summary())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-22T00:20:25.582832300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('../../assets/deep_assets/tuner_results_10_attempts.txt', 'w') as f:\n",
    "    f.write(str(tuner.results_summary()))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-22T00:20:25.584829500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tuner.get_best_hyperparameters()[0].values\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-22T00:20:25.587827900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tuner.save()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-22T00:20:25.589826600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_model = tuner.get_best_models()[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-22T00:20:25.591825700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-22T00:20:25.596823300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tuning fit hyperparamters using GridSearch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# model = Sequential([\n",
    "#     Embedding(input_dim=len(word_index), output_dim= 300, input_length=X_train.shape[1], trainable=False, weights=[embeddings_on_this_context]),\n",
    "#     Bidirectional(LSTM(64, return_sequences=True)),\n",
    "#     # Dropout(0.29),\n",
    "#     # Bidirectional(LSTM(hp.Choice('units',[32,64]))),\n",
    "#     Bidirectional(LSTM(64)),\n",
    "#     Dense(32, activation='relu'),\n",
    "#     # Dropout(0.73),\n",
    "#     Dense(4, activation='softmax')\n",
    "# ])\n",
    "#\n",
    "# model.summary()\n",
    "#\n",
    "# from keras.optimizers import SGD\n",
    "#\n",
    "# loss = \"sparse_categorical_crossentropy\"\n",
    "# optimizer = 'adam'\n",
    "# metrics = ['accuracy']\n",
    "#\n",
    "# model.compile(loss=loss,optimizer=optimizer,metrics=metrics)\n",
    "#\n",
    "# es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "#\n",
    "#\n",
    "# history = model.fit(X_train, y_train, epochs=4000, validation_data=(X_val,y_val), verbose=2, callbacks=[es])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-22T00:20:25.598821700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# def architecture_tuned_model():\n",
    "#     model = Sequential([\n",
    "#         Embedding(input_dim=len(word_index), output_dim=300, input_length=X_train.shape[1], trainable=False,\n",
    "#                   weights=[embeddings_on_this_context]),\n",
    "#         Bidirectional(LSTM(32, return_sequences=True)),\n",
    "#         Dropout(0.29),\n",
    "#         Bidirectional(LSTM(16)),\n",
    "#         Dense(64, 'tanh'),\n",
    "#         Dropout(0.73),\n",
    "#         Dense(4, activation='softmax')\n",
    "#     ])\n",
    "#     loss = \"sparse_categorical_crossentropy\"\n",
    "#     optimizer = 'adam'\n",
    "#     metrics = ['accuracy']\n",
    "#\n",
    "#     model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "#     return model\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-22T00:20:25.602819600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from keras.wrappers.scikit_learn import KerasClassifier\n",
    "#\n",
    "# model = KerasClassifier(build_fn=architecture_tuned_model, verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-22T00:20:25.605818500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "#\n",
    "# es = EarlyStopping(monitor='accuracy', mode='min', verbose=1, patience=5)\n",
    "#\n",
    "# param_grid = {'batch_size': [1,2,4,8]}\n",
    "#\n",
    "# gs = GridSearchCV(estimator=model,\n",
    "#                   param_grid=param_grid,\n",
    "#                   cv=5)\n",
    "# gs.fit(X_train, y_train, callbacks=[es])\n",
    "# print(f\"Best results for {model.__class__.__name__}\")\n",
    "# print(\"Best Score of train set: \" + str(gs.best_score_))\n",
    "# print(\"Best estimator: \" + str(gs.best_estimator_))\n",
    "# print(\"Best parameter set: \" + str(gs.best_params_))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-22T00:20:25.611814300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# gs.best_estimator_.model.history.history\n",
    "# # 0.7766810655593872"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-22T00:20:25.612814900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "# ax1.plot(gs.best_estimator_.model.history.history['accuracy'])\n",
    "# ax1.plot(gs.best_estimator_.model.history.history['loss'])\n",
    "# ax1.set_title('Model Accuracy')\n",
    "# ax1.set_ylabel('Accuracy')\n",
    "# ax1.set_xlabel('Epoch')\n",
    "# ax1.legend(['Train', 'Validation'], loc='upper left')\n",
    "#\n",
    "# ax2.plot(gs.best_estimator_.model.history.history['loss'])\n",
    "# ax2.plot(gs.best_estimator_.model.history.history['val_loss'])\n",
    "# ax2.set_title('Model Loss')\n",
    "# ax2.set_ylabel('Loss')\n",
    "# ax2.set_xlabel('Epoch')\n",
    "# ax2.legend(['Train', 'Validation'], loc='upper left')\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-22T00:20:25.616810900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tuning fit hyperparameters manually"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # model = Sequential([\n",
    "# #     Embedding(input_dim=len(word_index), output_dim= 300, input_length=X_train.shape[1], trainable=False, weights=[embeddings_on_this_context]),\n",
    "# #     Bidirectional(LSTM(4, return_sequences=True)),\n",
    "# #     # Dropout(0.29),\n",
    "# #     # Bidirectional(LSTM(hp.Choice('units',[32,64]))),\n",
    "# #     Bidirectional(LSTM(4)),\n",
    "# #     Dense(32, activation='relu'),\n",
    "# #     # Dropout(0.73),\n",
    "# #     Dense(4, activation='softmax')\n",
    "# # ])\n",
    "# #\n",
    "# # model.summary()\n",
    "#\n",
    "# from keras.optimizers import SGD\n",
    "#\n",
    "# loss = \"sparse_categorical_crossentropy\"\n",
    "# optimizer = 'adam'\n",
    "# metrics = [get_f1]\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "# best_model.compile(loss=loss,optimizer=optimizer,metrics=metrics)\n",
    "#\n",
    "# es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "#\n",
    "#\n",
    "# best_model.summary()\n",
    "#\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-22T00:20:25.619810100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# history = best_model.fit(X_train, y_train, epochs=4000, batch_size=32, validation_split=0.1, verbose=2, callbacks=[es])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-22T00:20:25.627806700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "# ax1.plot(history.history['accuracy'])\n",
    "# ax1.plot(history.history['val_accuracy'])\n",
    "# ax1.set_title('Model Accuracy')\n",
    "# ax1.set_ylabel('Accuracy')\n",
    "# ax1.set_xlabel('Epoch')\n",
    "# ax1.legend(['Train', 'Validation'], loc='upper left')\n",
    "#\n",
    "# ax2.plot(history.history['loss'])\n",
    "# ax2.plot(history.history['val_loss'])\n",
    "# ax2.set_title('Model Loss')\n",
    "# ax2.set_ylabel('Loss')\n",
    "# ax2.set_xlabel('Epoch')\n",
    "# ax2.legend(['Train', 'Validation'], loc='upper left')\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-22T00:20:25.629803600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Exporting model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_model.save('../../assets/deep_assets/lstm_model')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
