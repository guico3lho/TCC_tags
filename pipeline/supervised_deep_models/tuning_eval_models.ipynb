{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Packages and Assets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping\n",
    "import seaborn as sns\n",
    "import keras_tuner as kt\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing.text import tokenizer_from_json\n",
    "import os, sys"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-21T01:18:15.033972800Z",
     "start_time": "2023-05-21T01:17:34.585957Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guilherme\\.conda\\envs\\nlp2\\python.exe\n",
      "C:\\Users\\Guilherme\\Documents\\Programming\\Python\\DataScience\\TCC\\pipeline\\supervised_deep_models\n"
     ]
    }
   ],
   "source": [
    "print(sys.executable)\n",
    "print(os.getcwd())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-21T01:18:15.047936200Z",
     "start_time": "2023-05-21T01:18:15.035982500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dependencies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "with open('../../assets/deep_assets/tokenizer.json', 'r', encoding='utf-8') as f:\n",
    "    tokenizer_json = f.read()\n",
    "    tokenizer = tokenizer_from_json(tokenizer_json)\n",
    "    word_index = tokenizer.word_index\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-21T01:18:15.109900900Z",
     "start_time": "2023-05-21T01:18:15.048936300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('itub4', 0.9894438982009888), ('banco', 0.9625048041343689), ('bbas3', 0.9558351635932922), ('bbdc4', 0.9518388509750366), ('bradesco', 0.9462378621101379), ('santander', 0.9438444972038269), ('unibanco', 0.9431132078170776), ('valioso', 0.9285449981689453), ('xpbr31', 0.9095613956451416), ('pagara', 0.8953273892402649)]\n"
     ]
    }
   ],
   "source": [
    "model_we = Word2Vec.load('../../assets/deep_assets/word2vec.model')\n",
    "\n",
    "print(model_we.wv.most_similar('itau'))\n",
    "\n",
    "# List of nparrays of size 300\n",
    "embeddings_dict = {}\n",
    "for word in model_we.wv.index_to_key:\n",
    "    embeddings_dict[word] = model_we.wv[word]\n",
    "\n",
    "embeddings_on_this_context = np.zeros((len(word_index), 300))\n",
    "for word, i in word_index.items():\n",
    "    embeddings_vector = embeddings_dict.get(word)\n",
    "    if embeddings_vector is not None:\n",
    "        embeddings_on_this_context[i - 1] = embeddings_vector\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-21T01:18:15.210843500Z",
     "start_time": "2023-05-21T01:18:15.110901200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "train = pd.read_csv('../../assets/data/splits/train/padded.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-21T01:18:15.252819600Z",
     "start_time": "2023-05-21T01:18:15.204846200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def index2word(word_index):\n",
    "    index_word = {}\n",
    "    for key in word_index:\n",
    "        index_word[word_index[key]] = key\n",
    "    return index_word\n",
    "\n",
    "\n",
    "def seq2text(seq, index_word):\n",
    "    text = []\n",
    "    for index in seq:\n",
    "        text.append(index_word[index])\n",
    "    return text\n",
    "\n",
    "\n",
    "def show_confusion_matrix(cm):\n",
    "    print(\"Confusion Matrix\")\n",
    "    plt.figure(figsize=(10, 7))\n",
    "\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'],\n",
    "                yticklabels=['Negative', 'Positive'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Truth')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-21T01:18:15.268811200Z",
     "start_time": "2023-05-21T01:18:15.253819400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RNN Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data transformation for model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "X_train = train.to_numpy()[:, :-1]\n",
    "y_train = train.to_numpy()[:, -1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-21T01:18:15.284801Z",
     "start_time": "2023-05-21T01:18:15.269810200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tuning Architecture Hyperparams using RandomSearch and Early Stopping"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Test 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# def build_model(hp):\n",
    "#     model = Sequential([\n",
    "#         Embedding(input_dim=len(word_index), output_dim=300, input_length=X_train.shape[1], trainable=False,\n",
    "#                   weights=[embeddings_on_this_context]),\n",
    "#         Bidirectional(LSTM(16, return_sequences=True)),\n",
    "#         Dropout(hp.Float('rate_dp_1', 0, 0.4, step=0.1)),\n",
    "#         Bidirectional(LSTM(16)),\n",
    "#         Dense(64, 'tanh'),\n",
    "#         Dropout(hp.Float('rate_dp_1', 0.1, 0.4, step=0.1)),\n",
    "#         Dense(4, activation='softmax')\n",
    "#     ])\n",
    "#     loss = \"sparse_categorical_crossentropy\"\n",
    "#     # optimizer = SGD(learning_rate=0.01)\n",
    "#     metrics = ['accuracy']\n",
    "#\n",
    "#     model.compile(loss=loss, optimizer='adam', metrics=metrics)\n",
    "#     return model\n",
    "#\n",
    "#\n",
    "# es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-21T01:18:15.439712500Z",
     "start_time": "2023-05-21T01:18:15.288798400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "####  Test 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential([\n",
    "    Embedding(input_dim=len(word_index), output_dim= 300, input_length=X_train.shape[1], trainable=False, weights=[embeddings_on_this_context]),\n",
    "    Bidirectional(LSTM(hp.Choice('units_bilstm_1',[16,32,64]), return_sequences=True)),\n",
    "    Dropout(hp.Float('rate_dp_1',0,0.3,step=0.1)),\n",
    "    Bidirectional(LSTM(hp.Choice('units_bilstm_2',[16,32,64]))),\n",
    "    Dense(hp.Choice('units_dense',[16,32,64]), hp.Choice(['activation','tanh']) ),\n",
    "    Dropout(hp.Float('rate_dp_2',0,0.3,step=0.1)),\n",
    "    Dense(4, activation='softmax')\n",
    "])\n",
    "    loss = \"sparse_categorical_crossentropy\"\n",
    "    # optimizer = SGD(learning_rate=0.01)\n",
    "    metrics = ['accuracy']\n",
    "\n",
    "    model.compile(loss=loss,optimizer='adam',metrics=metrics)\n",
    "    return model\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-21T01:18:15.454703800Z",
     "start_time": "2023-05-21T01:18:15.445709300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 6\n",
      "units_bilstm_1 (Choice)\n",
      "{'default': 16, 'conditions': [], 'values': [16, 32, 64], 'ordered': True}\n",
      "rate_dp_1 (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.3, 'step': 0.1, 'sampling': 'linear'}\n",
      "units_bilstm_2 (Choice)\n",
      "{'default': 16, 'conditions': [], 'values': [16, 32, 64], 'ordered': True}\n",
      "units_dense (Choice)\n",
      "{'default': 16, 'conditions': [], 'values': [16, 32, 64], 'ordered': True}\n",
      "activation (Choice)\n",
      "{'default': 'tanh', 'conditions': [], 'values': ['tanh'], 'ordered': False}\n",
      "rate_dp_2 (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.3, 'step': 0.1, 'sampling': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# amanha testar dropout 0.0, 0.1, 0.2\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    directory='../../assets/deep_assets',\n",
    "    overwrite=True,\n",
    "    project_name='lstm_tuning')\n",
    "\n",
    "tuner.search_space_summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-21T01:18:17.202472Z",
     "start_time": "2023-05-21T01:18:15.453704600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "32                |32                |units_bilstm_1\n",
      "0                 |0                 |rate_dp_1\n",
      "64                |64                |units_bilstm_2\n",
      "32                |32                |units_dense\n",
      "tanh              |tanh              |activation\n",
      "0.1               |0.1               |rate_dp_2\n",
      "\n",
      "Epoch 1/4000\n",
      "456/456 - 20s - loss: 0.8084 - accuracy: 0.6948 - val_loss: 0.6433 - val_accuracy: 0.7730 - 20s/epoch - 45ms/step\n",
      "Epoch 2/4000\n",
      "456/456 - 12s - loss: 0.5932 - accuracy: 0.7866 - val_loss: 0.5427 - val_accuracy: 0.8063 - 12s/epoch - 27ms/step\n",
      "Epoch 3/4000\n",
      "456/456 - 9s - loss: 0.5328 - accuracy: 0.8092 - val_loss: 0.5344 - val_accuracy: 0.8236 - 9s/epoch - 19ms/step\n",
      "Epoch 4/4000\n",
      "456/456 - 7s - loss: 0.5043 - accuracy: 0.8219 - val_loss: 0.5033 - val_accuracy: 0.8236 - 7s/epoch - 16ms/step\n",
      "Epoch 5/4000\n",
      "456/456 - 8s - loss: 0.4844 - accuracy: 0.8279 - val_loss: 0.4849 - val_accuracy: 0.8260 - 8s/epoch - 18ms/step\n",
      "Epoch 6/4000\n",
      "456/456 - 6s - loss: 0.4754 - accuracy: 0.8310 - val_loss: 0.4787 - val_accuracy: 0.8254 - 6s/epoch - 13ms/step\n",
      "Epoch 7/4000\n",
      "456/456 - 11s - loss: 0.4645 - accuracy: 0.8337 - val_loss: 0.4743 - val_accuracy: 0.8341 - 11s/epoch - 24ms/step\n",
      "Epoch 8/4000\n",
      "456/456 - 9s - loss: 0.4511 - accuracy: 0.8402 - val_loss: 0.4743 - val_accuracy: 0.8316 - 9s/epoch - 20ms/step\n",
      "Epoch 9/4000\n",
      "456/456 - 8s - loss: 0.4443 - accuracy: 0.8413 - val_loss: 0.4844 - val_accuracy: 0.8353 - 8s/epoch - 17ms/step\n",
      "Epoch 10/4000\n",
      "456/456 - 7s - loss: 0.4293 - accuracy: 0.8474 - val_loss: 0.4718 - val_accuracy: 0.8316 - 7s/epoch - 14ms/step\n",
      "Epoch 11/4000\n",
      "456/456 - 6s - loss: 0.4171 - accuracy: 0.8502 - val_loss: 0.4782 - val_accuracy: 0.8304 - 6s/epoch - 12ms/step\n",
      "Epoch 12/4000\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train, epochs=4000, validation_split=0.1, callbacks=[es], batch_size=32, verbose=2)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-05-21T01:18:17.203471100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tuner.results_summary()\n",
    " # 0.845774233341217"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_model = tuner.get_best_models()[0]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tuning fit hyperparamters using GridSearch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# model = Sequential([\n",
    "#     Embedding(input_dim=len(word_index), output_dim= 300, input_length=X_train.shape[1], trainable=False, weights=[embeddings_on_this_context]),\n",
    "#     Bidirectional(LSTM(64, return_sequences=True)),\n",
    "#     # Dropout(0.29),\n",
    "#     # Bidirectional(LSTM(hp.Choice('units',[32,64]))),\n",
    "#     Bidirectional(LSTM(64)),\n",
    "#     Dense(32, activation='relu'),\n",
    "#     # Dropout(0.73),\n",
    "#     Dense(4, activation='softmax')\n",
    "# ])\n",
    "#\n",
    "# model.summary()\n",
    "#\n",
    "# from keras.optimizers import SGD\n",
    "#\n",
    "# loss = \"sparse_categorical_crossentropy\"\n",
    "# optimizer = 'adam'\n",
    "# metrics = ['accuracy']\n",
    "#\n",
    "# model.compile(loss=loss,optimizer=optimizer,metrics=metrics)\n",
    "#\n",
    "# es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "#\n",
    "#\n",
    "# history = model.fit(X_train, y_train, epochs=4000, validation_data=(X_val,y_val), verbose=2, callbacks=[es])\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# def architecture_tuned_model():\n",
    "#     model = Sequential([\n",
    "#         Embedding(input_dim=len(word_index), output_dim=300, input_length=X_train.shape[1], trainable=False,\n",
    "#                   weights=[embeddings_on_this_context]),\n",
    "#         Bidirectional(LSTM(32, return_sequences=True)),\n",
    "#         Dropout(0.29),\n",
    "#         Bidirectional(LSTM(16)),\n",
    "#         Dense(64, 'tanh'),\n",
    "#         Dropout(0.73),\n",
    "#         Dense(4, activation='softmax')\n",
    "#     ])\n",
    "#     loss = \"sparse_categorical_crossentropy\"\n",
    "#     optimizer = 'adam'\n",
    "#     metrics = ['accuracy']\n",
    "#\n",
    "#     model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "#     return model\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from keras.wrappers.scikit_learn import KerasClassifier\n",
    "#\n",
    "# model = KerasClassifier(build_fn=architecture_tuned_model, verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "#\n",
    "# es = EarlyStopping(monitor='accuracy', mode='min', verbose=1, patience=5)\n",
    "#\n",
    "# param_grid = {'batch_size': [1,2,4,8]}\n",
    "#\n",
    "# gs = GridSearchCV(estimator=model,\n",
    "#                   param_grid=param_grid,\n",
    "#                   cv=5)\n",
    "# gs.fit(X_train, y_train, callbacks=[es])\n",
    "# print(f\"Best results for {model.__class__.__name__}\")\n",
    "# print(\"Best Score of train set: \" + str(gs.best_score_))\n",
    "# print(\"Best estimator: \" + str(gs.best_estimator_))\n",
    "# print(\"Best parameter set: \" + str(gs.best_params_))\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# gs.best_estimator_.model.history.history\n",
    "# # 0.7766810655593872"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "# ax1.plot(gs.best_estimator_.model.history.history['accuracy'])\n",
    "# ax1.plot(gs.best_estimator_.model.history.history['loss'])\n",
    "# ax1.set_title('Model Accuracy')\n",
    "# ax1.set_ylabel('Accuracy')\n",
    "# ax1.set_xlabel('Epoch')\n",
    "# ax1.legend(['Train', 'Validation'], loc='upper left')\n",
    "#\n",
    "# ax2.plot(gs.best_estimator_.model.history.history['loss'])\n",
    "# ax2.plot(gs.best_estimator_.model.history.history['val_loss'])\n",
    "# ax2.set_title('Model Loss')\n",
    "# ax2.set_ylabel('Loss')\n",
    "# ax2.set_xlabel('Epoch')\n",
    "# ax2.legend(['Train', 'Validation'], loc='upper left')\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tuning fit hyperparameters manually"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=len(word_index), output_dim= 300, input_length=X_train.shape[1], trainable=False, weights=[embeddings_on_this_context]),\n",
    "    Bidirectional(LSTM(64, return_sequences=True)),\n",
    "    # Dropout(0.29),\n",
    "    # Bidirectional(LSTM(hp.Choice('units',[32,64]))),\n",
    "    Bidirectional(LSTM(64)),\n",
    "    Dense(32, activation='relu'),\n",
    "    # Dropout(0.73),\n",
    "    Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "loss = \"sparse_categorical_crossentropy\"\n",
    "optimizer = 'adam'\n",
    "metrics = ['accuracy']\n",
    "\n",
    "model.compile(loss=loss,optimizer=optimizer,metrics=metrics)\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=4000, validation_split=0.1, verbose=2, callbacks=[es])\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "ax1.plot(history.history['accuracy'])\n",
    "ax1.plot(history.history['loss'])\n",
    "ax1.set_title('Model Accuracy')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "ax2.plot(history.history['loss'])\n",
    "ax2.plot(history.history['val_loss'])\n",
    "ax2.set_title('Model Loss')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Exporting model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save('../../assets/deep_assets/lstm_model')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
