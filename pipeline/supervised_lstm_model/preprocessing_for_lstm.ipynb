{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Packages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def createVocabulary(corpus):\n",
    "    \"\"\"\n",
    "    - Cria vocab (palavra e sua respectiva frequência no corpus)\n",
    "    - Cria tokens (palavras do corpus)\n",
    "\n",
    "    :param corpus: lista de string\n",
    "    :return vocab, tokens, vocab_size:\n",
    "    \"\"\"\n",
    "    tokens = []  # {'deeds', 'old', ...} 71666\n",
    "    vocab = {}  # {'deeds': 2, 'old': 20', ...} 17971\n",
    "    for text in corpus:\n",
    "        for token in text.split():\n",
    "            tokens.append(token)\n",
    "            if token in vocab:\n",
    "                vocab[token] += 1\n",
    "            else:\n",
    "                vocab[token] = 1\n",
    "    vocab_size = len(vocab)\n",
    "    return tokens, vocab, vocab_size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def findMaxLen(sequence):\n",
    "    max_len = 0\n",
    "    for text in sequence:\n",
    "        if len(text) > max_len:\n",
    "            max_len = len(text)\n",
    "    return max_len\n",
    "\n",
    "def findAverageLen(sequence):\n",
    "    total_len = 0\n",
    "    for text in sequence:\n",
    "        total_len += len(text)\n",
    "    return total_len / len(sequence)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   title  \\\n0      dividendos as <NUM> acoes preferidas <NUM> ana...   \n1      itau jhsf banco brasil confira agenda resultad...   \n2      destaques empresas petrobras petr4 jbs jbss3 h...   \n3      itau unibanco itub4 vai pagar proventos comeco...   \n4      petrobras petr4 elege novo conselho maior part...   \n...                                                  ...   \n11951  petrobras guia nova maxima ibovespa sessao meg...   \n11952  petrobras estende vencimento emprestimo banco ...   \n11953  petrobras percepcao risco sobre politica preco...   \n11954  bndes espera vender cerca <NUM> bi debentures ...   \n11955  em ano ruim acoes bancos brasileiros podem sub...   \n\n                                                    tags  \\\n0      ['Carteira Recomendada', 'Comprar ou vender?',...   \n1      ['Alper (APER3)', 'balanços trimestrais', 'Bol...   \n2      ['Arezzo (ARZZ3)', 'Cia Hering (HGTX3)', 'dest...   \n3      ['Bancos', 'Dividendos', 'Empresas', 'Itaú Uni...   \n4      ['Ações', 'Adriano Pires', 'Combustíveis', 'Em...   \n...                                                  ...   \n11951  ['Ações', 'Empresas', 'Ibovespa', 'Leilão', 'M...   \n11952                          ['Empresas', 'Petrobras']   \n11953  ['Ações', 'Combustíveis', 'Commodities', 'Comp...   \n11954  ['BNDES', 'BNDESPar', 'debêntures', 'Vale (VAL...   \n11955  ['Ações', 'Banco do Brasil', 'Bancos', 'Brades...   \n\n                                                    link  label  \n0      https://www.moneytimes.com.br/dividendos-as-10...      1  \n1      https://www.suno.com.br/noticias/itau-jhsf-ban...      2  \n2      https://www.suno.com.br/noticias/destaques-de-...      0  \n3      https://www.moneytimes.com.br/itau-unibanco-it...      2  \n4      https://www.moneytimes.com.br/petrobras-petr4-...      0  \n...                                                  ...    ...  \n11951  https://www.moneytimes.com.br/petrobras-guia-n...      0  \n11952  https://www.moneytimes.com.br/petrobras-estend...      0  \n11953  https://www.moneytimes.com.br/petrobras-percep...      0  \n11954  https://www.suno.com.br/noticias/bndes-venda-d...      1  \n11955  https://www.moneytimes.com.br/em-ano-ruim-acoe...      2  \n\n[11956 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>tags</th>\n      <th>link</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>dividendos as &lt;NUM&gt; acoes preferidas &lt;NUM&gt; ana...</td>\n      <td>['Carteira Recomendada', 'Comprar ou vender?',...</td>\n      <td>https://www.moneytimes.com.br/dividendos-as-10...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>itau jhsf banco brasil confira agenda resultad...</td>\n      <td>['Alper (APER3)', 'balanços trimestrais', 'Bol...</td>\n      <td>https://www.suno.com.br/noticias/itau-jhsf-ban...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>destaques empresas petrobras petr4 jbs jbss3 h...</td>\n      <td>['Arezzo (ARZZ3)', 'Cia Hering (HGTX3)', 'dest...</td>\n      <td>https://www.suno.com.br/noticias/destaques-de-...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>itau unibanco itub4 vai pagar proventos comeco...</td>\n      <td>['Bancos', 'Dividendos', 'Empresas', 'Itaú Uni...</td>\n      <td>https://www.moneytimes.com.br/itau-unibanco-it...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>petrobras petr4 elege novo conselho maior part...</td>\n      <td>['Ações', 'Adriano Pires', 'Combustíveis', 'Em...</td>\n      <td>https://www.moneytimes.com.br/petrobras-petr4-...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>11951</th>\n      <td>petrobras guia nova maxima ibovespa sessao meg...</td>\n      <td>['Ações', 'Empresas', 'Ibovespa', 'Leilão', 'M...</td>\n      <td>https://www.moneytimes.com.br/petrobras-guia-n...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11952</th>\n      <td>petrobras estende vencimento emprestimo banco ...</td>\n      <td>['Empresas', 'Petrobras']</td>\n      <td>https://www.moneytimes.com.br/petrobras-estend...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11953</th>\n      <td>petrobras percepcao risco sobre politica preco...</td>\n      <td>['Ações', 'Combustíveis', 'Commodities', 'Comp...</td>\n      <td>https://www.moneytimes.com.br/petrobras-percep...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11954</th>\n      <td>bndes espera vender cerca &lt;NUM&gt; bi debentures ...</td>\n      <td>['BNDES', 'BNDESPar', 'debêntures', 'Vale (VAL...</td>\n      <td>https://www.suno.com.br/noticias/bndes-venda-d...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11955</th>\n      <td>em ano ruim acoes bancos brasileiros podem sub...</td>\n      <td>['Ações', 'Banco do Brasil', 'Bancos', 'Brades...</td>\n      <td>https://www.moneytimes.com.br/em-ano-ruim-acoe...</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>11956 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pp = pd.read_csv('../../assets/df_pp.csv')\n",
    "df_pp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Splitting Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "X = df_pp.title\n",
    "y = df_pp.label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Split data into train and test\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X, y, train_size=0.8, random_state=52)  # 80% train\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_rem, y_rem, test_size=0.5, random_state=52)  # 10% val, 10% testc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4877\n",
      "1    3007\n",
      "2    1680\n",
      "Name: label, dtype: int64\n",
      "0    646\n",
      "1    349\n",
      "2    201\n",
      "Name: label, dtype: int64\n",
      "0    590\n",
      "1    384\n",
      "2    222\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts())\n",
    "print(y_val.value_counts())\n",
    "print(y_test.value_counts())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tokenization, Vocabulary"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "8010"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens, vocab, vocab_size = createVocabulary(X_train)\n",
    "len(vocab)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Numericalization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "word_index = tokenizer.word_index\n",
    "train_sequences = tokenizer.texts_to_sequences(X_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Padding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "max_len = findMaxLen(train_sequences)\n",
    "max_len = int(max_len/2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "train_padded = pad_sequences(train_sequences, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "val_sequences = tokenizer.texts_to_sequences(X_val)\n",
    "val_padded = pad_sequences(val_sequences, maxlen=max_len, padding='post', truncating='post')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load word2vec model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "[('petr4', 0.9948422312736511),\n ('diz', 0.9689343571662903),\n ('combustiveis', 0.9598903656005859),\n ('bolsonaro', 0.9582469463348389),\n ('intervir', 0.9552468657493591),\n ('sal', 0.9517554640769958),\n ('gas', 0.9510222673416138),\n ('venda', 0.9506813883781433),\n ('natural', 0.9480621814727783),\n ('premenos', 0.9469091296195984)]"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Word2Vec.load('../../assets/word2vec.model')\n",
    "\n",
    "model.wv.most_similar('petrobras')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "# List of nparrays of size 300\n",
    "embeddings_dict = {}\n",
    "for i, word in enumerate(model.wv.index_to_key):\n",
    "    embeddings_dict[word] = model.wv[word]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "# create matrix with vocab train words\n",
    "embeddings_matrix = np.zeros((len(word_index),300))\n",
    "for word, i in word_index.items():\n",
    "    embeddings_vector = embeddings_dict.get(word)\n",
    "    if embeddings_vector is not None:\n",
    "        embeddings_matrix[i-1] = embeddings_vector"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RNN Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Packages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from keras.losses import BinaryCrossentropy\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "def index2word(word_index):\n",
    "    index_word = {}\n",
    "    for key in word_index:\n",
    "        index_word[word_index[key]] = key\n",
    "    return index_word\n",
    "\n",
    "\n",
    "def seq2text(seq, index_word):\n",
    "    text = []\n",
    "    for index in seq:\n",
    "        text.append(index_word[index])\n",
    "    return text\n",
    "\n",
    "def show_confusion_matrix(cm):\n",
    "        print(\"Confusion Matrix\")\n",
    "        plt.figure(figsize=(10, 7))\n",
    "\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'],\n",
    "                    yticklabels=['Negative', 'Positive'])\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Truth')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Declaration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 11, 300)           2403300   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 11, 512)          1140736   \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 11, 512)           0         \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 512)              1574912   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                16416     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,135,397\n",
      "Trainable params: 2,732,097\n",
      "Non-trainable params: 2,403,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size+1, output_dim= 300,input_length=max_len, trainable=False, weights=[embeddings_matrix]),\n",
    "    Bidirectional(LSTM(256, return_sequences=True)),\n",
    "    Dropout(0.6),\n",
    "    # Bidirectional(LSTM(hp.Choice('units',[32,64]))),\n",
    "    Bidirectional(LSTM(256)),\n",
    "    Dense(32, activation='relu'),\n",
    "    # Dropout(0.6),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "299/299 - 109s - loss: -6.4533e-01 - accuracy: 0.5332 - val_loss: -1.7918e+00 - val_accuracy: 0.6555 - 109s/epoch - 366ms/step\n",
      "Epoch 2/30\n"
     ]
    }
   ],
   "source": [
    "loss = BinaryCrossentropy(from_logits=False)\n",
    "optimizer = Adam(0.0001)\n",
    "metrics = ['accuracy']\n",
    "model.compile(loss=loss,optimizer=optimizer,metrics=metrics)\n",
    "\n",
    "history = model.fit(train_padded, y_train, epochs=30, validation_data=(val_padded,y_val), verbose=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "ax1.plot(history.history['accuracy'])\n",
    "ax1.plot(history.history['val_accuracy'])\n",
    "ax1.set_title('Model Accuracy')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "ax2.plot(history.history['loss'])\n",
    "ax2.plot(history.history['val_loss'])\n",
    "ax2.set_title('Model Loss')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "test_padded = pad_sequences(test_sequences, maxlen=max_len, padding='post', truncating='post')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "index_word = index2word(word_index)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred_prob = model.predict(test_padded)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred = [1 if p > 0.5 else 0 for p in pred_prob]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame()\n",
    "X_test = list(X_test)\n",
    "y_test = list(y_test)\n",
    "df_results['sequence'] = test_sequences\n",
    "df_results['X_test'] = X_test\n",
    "df_results['seq2text'] = df_results['sequence'].apply(lambda x: seq2text(x, index_word))\n",
    "df_results['y_pred'] = y_pred\n",
    "df_results['y_true'] = y_test\n",
    "df_results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "precision = precision_score(y_test,y_pred)\n",
    "recall = recall_score(y_test,y_pred)\n",
    "f1score = f1_score(y_test,y_pred)\n",
    "cm = confusion_matrix(y_test,y_pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))\n",
    "show_confusion_matrix(cm)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
